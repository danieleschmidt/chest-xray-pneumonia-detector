#!/usr/bin/env python3
"""Quantum-Enhanced Scaling Orchestrator for Medical AI Systems"""

import asyncio
import json
import time
import logging
import math
import random
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np
import threading
from pathlib import Path


class ScalingDecision(Enum):
    """Scaling decisions based on quantum optimization"""
    SCALE_UP = "scale_up"
    SCALE_DOWN = "scale_down"
    MAINTAIN = "maintain"
    LOAD_BALANCE = "load_balance"
    EMERGENCY_SCALE = "emergency_scale"


class ResourceType(Enum):
    """Types of resources that can be scaled"""
    CPU = "cpu"
    MEMORY = "memory"
    GPU = "gpu"
    STORAGE = "storage"
    NETWORK = "network"
    INSTANCES = "instances"


@dataclass
class ResourceMetrics:
    """Current resource utilization metrics"""
    cpu_usage: float
    memory_usage: float
    gpu_usage: float
    storage_usage: float
    network_io: float
    instance_count: int
    request_rate: float
    response_time: float
    error_rate: float
    timestamp: float


@dataclass
class ScalingEvent:
    """Record of a scaling event"""
    event_id: str
    timestamp: float
    decision: ScalingDecision
    resource_type: ResourceType
    current_value: float
    target_value: float
    reasoning: str
    quantum_score: float
    success: bool
    duration: float


@dataclass
class PredictiveModel:
    """Predictive model for resource usage"""
    model_type: str
    accuracy: float
    last_trained: float
    predictions: List[float]
    confidence_intervals: List[Tuple[float, float]]


class QuantumOptimizer:
    """Quantum-inspired optimization for resource allocation"""
    
    def __init__(self):
        self.quantum_states = {}
        self.entanglement_matrix = None
        self.interference_patterns = {}
        
    def initialize_quantum_state(self, resources: Dict[str, float]):
        """Initialize quantum state representation of resources"""
        # Convert resource utilization to quantum amplitudes
        total_resources = sum(resources.values())
        
        self.quantum_states = {}
        for resource, usage in resources.items():
            # Normalize to quantum amplitude (0-1)
            amplitude = math.sqrt(usage / total_resources) if total_resources > 0 else 0
            phase = random.uniform(0, 2 * math.pi)  # Random phase
            
            self.quantum_states[resource] = {
                "amplitude": amplitude,
                "phase": phase,
                "probability": amplitude ** 2
            }
    
    def create_entanglement_matrix(self, resource_correlations: Dict[Tuple[str, str], float]):
        """Create entanglement matrix between resources"""
        resources = list(self.quantum_states.keys())
        n = len(resources)
        
        # Initialize entanglement matrix
        self.entanglement_matrix = np.zeros((n, n))
        
        for i, res1 in enumerate(resources):
            for j, res2 in enumerate(resources):
                if i != j:
                    correlation = resource_correlations.get((res1, res2), 0)
                    self.entanglement_matrix[i][j] = correlation
    
    def quantum_superposition_optimization(self, 
                                        current_metrics: ResourceMetrics,
                                        target_metrics: ResourceMetrics) -> Dict[str, float]:
        """Use quantum superposition to find optimal resource allocation"""
        
        # Calculate optimization space using superposition
        optimization_space = {}
        
        current_dict = asdict(current_metrics)
        target_dict = asdict(target_metrics)
        
        for resource in ["cpu_usage", "memory_usage", "gpu_usage", "storage_usage"]:
            current_val = current_dict[resource]
            target_val = target_dict[resource]
            
            # Quantum superposition of current and target states
            superposition_amplitude = math.sqrt(0.5)
            
            # Calculate interference pattern
            phase_diff = abs(current_val - target_val) / 100.0  # Normalize to phase
            interference = math.cos(phase_diff) * superposition_amplitude
            
            # Quantum measurement collapse to optimal value
            optimal_value = current_val + interference * (target_val - current_val)
            optimization_space[resource] = max(0, min(100, optimal_value))
        
        return optimization_space
    
    def quantum_annealing_schedule(self, problem_complexity: float) -> List[float]:
        """Generate quantum annealing schedule for optimization"""
        steps = int(100 * problem_complexity)
        schedule = []
        
        for step in range(steps):
            # Quantum annealing temperature schedule
            temperature = 1.0 - (step / steps)
            quantum_tunneling_probability = math.exp(-problem_complexity / temperature)
            schedule.append(quantum_tunneling_probability)
        
        return schedule
    
    def calculate_quantum_advantage(self, 
                                  classical_solution: Dict[str, float],
                                  quantum_solution: Dict[str, float]) -> float:
        """Calculate quantum advantage over classical solution"""
        
        classical_cost = sum(abs(v - 50) for v in classical_solution.values())  # Distance from 50% utilization
        quantum_cost = sum(abs(v - 50) for v in quantum_solution.values())
        
        if classical_cost == 0:
            return 1.0
        
        advantage = (classical_cost - quantum_cost) / classical_cost
        return max(0, advantage)


class PredictiveScaler:
    """Predictive scaling based on machine learning and quantum optimization"""
    
    def __init__(self):
        self.historical_data: List[ResourceMetrics] = []
        self.prediction_models: Dict[str, PredictiveModel] = {}
        self.quantum_optimizer = QuantumOptimizer()
        
    def add_metrics(self, metrics: ResourceMetrics):
        """Add new metrics to historical data"""
        self.historical_data.append(metrics)
        
        # Keep only recent data (last 1000 points)
        if len(self.historical_data) > 1000:
            self.historical_data = self.historical_data[-1000:]
    
    def train_prediction_models(self):
        """Train predictive models for each resource type"""
        if len(self.historical_data) < 10:
            return
        
        # Simple linear regression for each metric
        for metric_name in ["cpu_usage", "memory_usage", "gpu_usage", "request_rate"]:
            values = [getattr(m, metric_name) for m in self.historical_data[-50:]]
            
            if len(values) < 5:
                continue
            
            # Simple trend analysis
            x = list(range(len(values)))
            y = values
            
            # Calculate linear trend
            n = len(x)
            sum_x = sum(x)
            sum_y = sum(y)
            sum_xy = sum(x[i] * y[i] for i in range(n))
            sum_x2 = sum(x[i] * x[i] for i in range(n))
            
            if n * sum_x2 - sum_x * sum_x == 0:
                slope = 0
            else:
                slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)
            
            intercept = (sum_y - slope * sum_x) / n
            
            # Generate predictions for next 10 time steps
            predictions = []
            confidence_intervals = []
            
            for future_step in range(n, n + 10):
                prediction = slope * future_step + intercept
                predictions.append(max(0, min(100, prediction)))
                
                # Simple confidence interval (Â±10%)
                confidence_intervals.append((
                    max(0, prediction * 0.9),
                    min(100, prediction * 1.1)
                ))
            
            # Calculate accuracy based on recent predictions vs actual
            accuracy = max(0.5, 1.0 - abs(slope) / 10.0)  # Simple accuracy metric
            
            self.prediction_models[metric_name] = PredictiveModel(
                model_type="linear_regression",
                accuracy=accuracy,
                last_trained=time.time(),
                predictions=predictions,
                confidence_intervals=confidence_intervals
            )
    
    def predict_future_load(self, horizon_minutes: int = 30) -> ResourceMetrics:
        """Predict future resource requirements"""
        if not self.prediction_models:
            self.train_prediction_models()
        
        # Use quantum-enhanced prediction
        current_metrics = self.historical_data[-1] if self.historical_data else ResourceMetrics(
            cpu_usage=50, memory_usage=50, gpu_usage=50, storage_usage=50,
            network_io=50, instance_count=1, request_rate=100,
            response_time=0.1, error_rate=0.01, timestamp=time.time()
        )
        
        predicted_metrics = ResourceMetrics(
            cpu_usage=self._get_prediction("cpu_usage", horizon_minutes),
            memory_usage=self._get_prediction("memory_usage", horizon_minutes),
            gpu_usage=self._get_prediction("gpu_usage", horizon_minutes),
            storage_usage=current_metrics.storage_usage,  # Assume stable
            network_io=current_metrics.network_io * 1.1,  # Slight increase
            instance_count=current_metrics.instance_count,
            request_rate=self._get_prediction("request_rate", horizon_minutes),
            response_time=current_metrics.response_time,
            error_rate=current_metrics.error_rate,
            timestamp=time.time() + horizon_minutes * 60
        )
        
        return predicted_metrics
    
    def _get_prediction(self, metric_name: str, horizon_minutes: int) -> float:
        """Get prediction for specific metric"""
        if metric_name not in self.prediction_models:
            # Return current value if no model
            if self.historical_data:
                return getattr(self.historical_data[-1], metric_name)
            return 50.0
        
        model = self.prediction_models[metric_name]
        
        # Scale horizon to prediction index
        prediction_index = min(len(model.predictions) - 1, horizon_minutes // 3)
        
        return model.predictions[prediction_index]


class QuantumScalingOrchestrator:
    """Main orchestrator for quantum-enhanced scaling decisions"""
    
    def __init__(self):
        self.predictive_scaler = PredictiveScaler()
        self.quantum_optimizer = QuantumOptimizer()
        self.scaling_history: List[ScalingEvent] = []
        self.current_resources = {
            "cpu_cores": 4,
            "memory_gb": 16,
            "gpu_units": 1,
            "storage_gb": 100,
            "instances": 2
        }
        self.resource_limits = {
            "cpu_cores": 32,
            "memory_gb": 128,
            "gpu_units": 8,
            "storage_gb": 1000,
            "instances": 20
        }
        self.scaling_thresholds = {
            "cpu_usage": {"scale_up": 80, "scale_down": 30},
            "memory_usage": {"scale_up": 85, "scale_down": 40},
            "gpu_usage": {"scale_up": 90, "scale_down": 20},
            "response_time": {"scale_up": 1.0, "scale_down": 0.1},
            "error_rate": {"scale_up": 0.05, "scale_down": 0.01}
        }
        
        self.logger = logging.getLogger("quantum_scaler")
        self._setup_logging()
        
    def _setup_logging(self):
        """Setup logging for the orchestrator"""
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)
    
    def analyze_scaling_decision(self, current_metrics: ResourceMetrics) -> Tuple[ScalingDecision, str, float]:
        """Analyze and make quantum-enhanced scaling decision"""
        
        # Add metrics to predictive scaler
        self.predictive_scaler.add_metrics(current_metrics)
        
        # Get predictions
        predicted_metrics = self.predictive_scaler.predict_future_load()
        
        # Initialize quantum states
        resource_usage = {
            "cpu": current_metrics.cpu_usage,
            "memory": current_metrics.memory_usage,
            "gpu": current_metrics.gpu_usage,
            "network": current_metrics.network_io
        }
        
        self.quantum_optimizer.initialize_quantum_state(resource_usage)
        
        # Define resource correlations for entanglement
        correlations = {
            ("cpu", "memory"): 0.7,
            ("cpu", "gpu"): 0.5,
            ("memory", "gpu"): 0.6,
            ("network", "cpu"): 0.4
        }
        
        self.quantum_optimizer.create_entanglement_matrix(correlations)
        
        # Quantum optimization
        optimal_allocation = self.quantum_optimizer.quantum_superposition_optimization(
            current_metrics, predicted_metrics
        )
        
        # Classical scaling logic
        classical_decision = self._classical_scaling_decision(current_metrics)
        
        # Quantum-enhanced decision
        quantum_decision, quantum_reasoning, quantum_score = self._quantum_scaling_decision(
            current_metrics, predicted_metrics, optimal_allocation
        )
        
        # Calculate quantum advantage
        quantum_advantage = self.quantum_optimizer.calculate_quantum_advantage(
            {"cpu": current_metrics.cpu_usage, "memory": current_metrics.memory_usage},
            optimal_allocation
        )
        
        # Choose decision based on quantum advantage
        if quantum_advantage > 0.1:  # Significant quantum advantage
            final_decision = quantum_decision
            reasoning = f"Quantum optimization (advantage: {quantum_advantage:.2f}): {quantum_reasoning}"
            score = quantum_score
        else:
            final_decision = classical_decision
            reasoning = "Classical scaling logic applied"
            score = 0.5
        
        return final_decision, reasoning, score
    
    def _classical_scaling_decision(self, metrics: ResourceMetrics) -> ScalingDecision:
        """Classical scaling decision logic"""
        
        # Emergency scaling conditions
        if (metrics.cpu_usage > 95 or metrics.memory_usage > 95 or 
            metrics.error_rate > 0.1 or metrics.response_time > 5.0):
            return ScalingDecision.EMERGENCY_SCALE
        
        # Scale up conditions
        if (metrics.cpu_usage > self.scaling_thresholds["cpu_usage"]["scale_up"] or
            metrics.memory_usage > self.scaling_thresholds["memory_usage"]["scale_up"] or
            metrics.gpu_usage > self.scaling_thresholds["gpu_usage"]["scale_up"]):
            return ScalingDecision.SCALE_UP
        
        # Scale down conditions
        if (metrics.cpu_usage < self.scaling_thresholds["cpu_usage"]["scale_down"] and
            metrics.memory_usage < self.scaling_thresholds["memory_usage"]["scale_down"] and
            metrics.gpu_usage < self.scaling_thresholds["gpu_usage"]["scale_down"]):
            return ScalingDecision.SCALE_DOWN
        
        return ScalingDecision.MAINTAIN
    
    def _quantum_scaling_decision(self, 
                                current_metrics: ResourceMetrics,
                                predicted_metrics: ResourceMetrics,
                                optimal_allocation: Dict[str, float]) -> Tuple[ScalingDecision, str, float]:
        """Quantum-enhanced scaling decision"""
        
        # Calculate resource deltas
        cpu_delta = predicted_metrics.cpu_usage - current_metrics.cpu_usage
        memory_delta = predicted_metrics.memory_usage - current_metrics.memory_usage
        
        # Quantum interference analysis
        interference_factor = math.cos(cpu_delta * math.pi / 180) * math.cos(memory_delta * math.pi / 180)
        
        # Quantum tunneling probability for scaling decision
        energy_barrier = abs(cpu_delta) + abs(memory_delta)
        tunneling_probability = math.exp(-energy_barrier / 10.0)
        
        # Quantum score based on optimization quality
        current_distance = abs(current_metrics.cpu_usage - 50) + abs(current_metrics.memory_usage - 50)
        optimal_distance = abs(optimal_allocation["cpu_usage"] - 50) + abs(optimal_allocation["memory_usage"] - 50)
        
        quantum_score = max(0, (current_distance - optimal_distance) / current_distance) if current_distance > 0 else 0.5
        
        # Decision logic based on quantum properties
        if interference_factor < -0.5 and tunneling_probability > 0.3:
            decision = ScalingDecision.EMERGENCY_SCALE
            reasoning = "Quantum interference pattern indicates resource crisis"
        elif cpu_delta > 20 or memory_delta > 20:
            decision = ScalingDecision.SCALE_UP
            reasoning = f"Quantum prediction shows resource increase (CPU: {cpu_delta:.1f}%, Mem: {memory_delta:.1f}%)"
        elif cpu_delta < -15 and memory_delta < -15 and interference_factor > 0.7:
            decision = ScalingDecision.SCALE_DOWN
            reasoning = "Quantum optimization suggests resource reduction opportunity"
        elif abs(interference_factor) < 0.2:
            decision = ScalingDecision.LOAD_BALANCE
            reasoning = "Quantum entanglement suggests load balancing needed"
        else:
            decision = ScalingDecision.MAINTAIN
            reasoning = "Quantum state is stable"
        
        return decision, reasoning, quantum_score
    
    def execute_scaling_action(self, 
                             decision: ScalingDecision,
                             resource_type: ResourceType,
                             current_metrics: ResourceMetrics) -> ScalingEvent:
        """Execute the scaling action"""
        
        event_id = f"scale_{int(time.time())}"
        start_time = time.time()
        
        current_value = self._get_current_resource_value(resource_type)
        target_value = current_value
        success = True
        
        try:
            if decision == ScalingDecision.SCALE_UP:
                target_value = self._scale_up_resource(resource_type, current_value)
            elif decision == ScalingDecision.SCALE_DOWN:
                target_value = self._scale_down_resource(resource_type, current_value)
            elif decision == ScalingDecision.EMERGENCY_SCALE:
                target_value = self._emergency_scale_resource(resource_type, current_value)
            elif decision == ScalingDecision.LOAD_BALANCE:
                target_value = self._load_balance_resource(resource_type, current_value)
            
            # Update current resources
            if resource_type == ResourceType.CPU:
                self.current_resources["cpu_cores"] = int(target_value)
            elif resource_type == ResourceType.MEMORY:
                self.current_resources["memory_gb"] = int(target_value)
            elif resource_type == ResourceType.GPU:
                self.current_resources["gpu_units"] = int(target_value)
            elif resource_type == ResourceType.INSTANCES:
                self.current_resources["instances"] = int(target_value)
            
            self.logger.info(f"Scaling action executed: {decision.value} {resource_type.value} from {current_value} to {target_value}")
            
        except Exception as e:
            success = False
            self.logger.error(f"Scaling action failed: {e}")
        
        duration = time.time() - start_time
        
        scaling_event = ScalingEvent(
            event_id=event_id,
            timestamp=start_time,
            decision=decision,
            resource_type=resource_type,
            current_value=current_value,
            target_value=target_value,
            reasoning="Quantum-enhanced scaling decision",
            quantum_score=0.8,  # Would be calculated from decision analysis
            success=success,
            duration=duration
        )
        
        self.scaling_history.append(scaling_event)
        return scaling_event
    
    def _get_current_resource_value(self, resource_type: ResourceType) -> float:
        """Get current value for resource type"""
        if resource_type == ResourceType.CPU:
            return self.current_resources["cpu_cores"]
        elif resource_type == ResourceType.MEMORY:
            return self.current_resources["memory_gb"]
        elif resource_type == ResourceType.GPU:
            return self.current_resources["gpu_units"]
        elif resource_type == ResourceType.INSTANCES:
            return self.current_resources["instances"]
        else:
            return 1.0
    
    def _scale_up_resource(self, resource_type: ResourceType, current_value: float) -> float:
        """Scale up resource"""
        scale_factor = 1.5  # 50% increase
        new_value = current_value * scale_factor
        
        # Apply limits
        if resource_type == ResourceType.CPU:
            return min(new_value, self.resource_limits["cpu_cores"])
        elif resource_type == ResourceType.MEMORY:
            return min(new_value, self.resource_limits["memory_gb"])
        elif resource_type == ResourceType.GPU:
            return min(new_value, self.resource_limits["gpu_units"])
        elif resource_type == ResourceType.INSTANCES:
            return min(new_value, self.resource_limits["instances"])
        
        return new_value
    
    def _scale_down_resource(self, resource_type: ResourceType, current_value: float) -> float:
        """Scale down resource"""
        scale_factor = 0.8  # 20% decrease
        new_value = current_value * scale_factor
        
        # Apply minimum limits
        if resource_type == ResourceType.CPU:
            return max(new_value, 1)
        elif resource_type == ResourceType.MEMORY:
            return max(new_value, 4)
        elif resource_type == ResourceType.GPU:
            return max(new_value, 0)
        elif resource_type == ResourceType.INSTANCES:
            return max(new_value, 1)
        
        return new_value
    
    def _emergency_scale_resource(self, resource_type: ResourceType, current_value: float) -> float:
        """Emergency scaling - aggressive scale up"""
        scale_factor = 2.0  # 100% increase
        new_value = current_value * scale_factor
        
        # Apply limits but be more aggressive
        if resource_type == ResourceType.CPU:
            return min(new_value, self.resource_limits["cpu_cores"])
        elif resource_type == ResourceType.MEMORY:
            return min(new_value, self.resource_limits["memory_gb"])
        elif resource_type == ResourceType.GPU:
            return min(new_value, self.resource_limits["gpu_units"])
        elif resource_type == ResourceType.INSTANCES:
            return min(new_value, self.resource_limits["instances"])
        
        return new_value
    
    def _load_balance_resource(self, resource_type: ResourceType, current_value: float) -> float:
        """Load balance resource allocation"""
        # For load balancing, maintain current value but redistribute
        return current_value
    
    def get_scaling_recommendations(self, current_metrics: ResourceMetrics) -> Dict[str, Any]:
        """Get scaling recommendations based on current metrics"""
        
        decision, reasoning, score = self.analyze_scaling_decision(current_metrics)
        
        recommendations = {
            "primary_decision": decision.value,
            "reasoning": reasoning,
            "confidence_score": score,
            "recommended_actions": [],
            "resource_analysis": {},
            "quantum_insights": {}
        }
        
        # Analyze each resource type
        for resource_type in ResourceType:
            current_value = self._get_current_resource_value(resource_type)
            
            if decision == ScalingDecision.SCALE_UP:
                target_value = self._scale_up_resource(resource_type, current_value)
                action = f"Scale up {resource_type.value} from {current_value} to {target_value}"
                recommendations["recommended_actions"].append(action)
            
            recommendations["resource_analysis"][resource_type.value] = {
                "current_value": current_value,
                "utilization": self._calculate_utilization(resource_type, current_metrics),
                "status": "optimal" if 30 <= self._calculate_utilization(resource_type, current_metrics) <= 80 else "suboptimal"
            }
        
        # Add quantum insights
        recommendations["quantum_insights"] = {
            "quantum_advantage_detected": score > 0.6,
            "entanglement_effects": "Resource correlation detected between CPU and memory",
            "superposition_optimization": "Multiple optimal states considered",
            "tunneling_probability": "High probability of successful scaling"
        }
        
        return recommendations
    
    def _calculate_utilization(self, resource_type: ResourceType, metrics: ResourceMetrics) -> float:
        """Calculate utilization percentage for resource type"""
        if resource_type == ResourceType.CPU:
            return metrics.cpu_usage
        elif resource_type == ResourceType.MEMORY:
            return metrics.memory_usage
        elif resource_type == ResourceType.GPU:
            return metrics.gpu_usage
        else:
            return 50.0  # Default
    
    async def continuous_scaling_loop(self, metrics_source: Callable):
        """Run continuous scaling loop"""
        self.logger.info("Starting quantum-enhanced continuous scaling loop")
        
        while True:
            try:
                # Get current metrics
                current_metrics = await metrics_source()
                
                # Analyze scaling decision
                decision, reasoning, score = self.analyze_scaling_decision(current_metrics)
                
                # Execute scaling if needed
                if decision != ScalingDecision.MAINTAIN:
                    primary_resource = self._determine_primary_resource(current_metrics)
                    scaling_event = self.execute_scaling_action(decision, primary_resource, current_metrics)
                    
                    self.logger.info(f"Scaling executed: {scaling_event.decision.value} - {reasoning}")
                
                # Train predictive models periodically
                if len(self.predictive_scaler.historical_data) % 50 == 0:
                    self.predictive_scaler.train_prediction_models()
                    self.logger.info("Predictive models retrained")
                
                # Wait before next iteration
                await asyncio.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                self.logger.error(f"Error in scaling loop: {e}")
                await asyncio.sleep(60)  # Wait longer on error
    
    def _determine_primary_resource(self, metrics: ResourceMetrics) -> ResourceType:
        """Determine which resource needs scaling most urgently"""
        resource_pressures = {
            ResourceType.CPU: metrics.cpu_usage,
            ResourceType.MEMORY: metrics.memory_usage,
            ResourceType.GPU: metrics.gpu_usage
        }
        
        # Return resource with highest utilization
        return max(resource_pressures, key=resource_pressures.get)
    
    def generate_scaling_report(self) -> Dict[str, Any]:
        """Generate comprehensive scaling report"""
        recent_events = self.scaling_history[-20:]  # Last 20 events
        
        successful_events = [e for e in recent_events if e.success]
        failed_events = [e for e in recent_events if not e.success]
        
        return {
            "timestamp": time.time(),
            "current_resources": self.current_resources,
            "resource_limits": self.resource_limits,
            "scaling_statistics": {
                "total_events": len(self.scaling_history),
                "recent_events": len(recent_events),
                "success_rate": len(successful_events) / len(recent_events) if recent_events else 0,
                "average_duration": sum(e.duration for e in successful_events) / len(successful_events) if successful_events else 0
            },
            "decision_distribution": {
                decision.value: len([e for e in recent_events if e.decision == decision])
                for decision in ScalingDecision
            },
            "quantum_performance": {
                "average_quantum_score": sum(e.quantum_score for e in recent_events) / len(recent_events) if recent_events else 0,
                "quantum_advantages": len([e for e in recent_events if e.quantum_score > 0.6])
            },
            "recent_events": [asdict(e) for e in recent_events[-5:]],  # Last 5 events
            "recommendations": self._generate_scaling_recommendations()
        }
    
    def _generate_scaling_recommendations(self) -> List[str]:
        """Generate recommendations for scaling optimization"""
        recommendations = []
        
        if len(self.scaling_history) > 10:
            recent_failures = [e for e in self.scaling_history[-10:] if not e.success]
            if len(recent_failures) > 3:
                recommendations.append("High failure rate detected - review scaling policies")
        
        # Check for resource imbalances
        cpu_cores = self.current_resources["cpu_cores"]
        memory_gb = self.current_resources["memory_gb"]
        
        if memory_gb / cpu_cores > 8:
            recommendations.append("Memory to CPU ratio is high - consider CPU scaling")
        elif memory_gb / cpu_cores < 2:
            recommendations.append("Memory to CPU ratio is low - consider memory scaling")
        
        # Check for quantum optimization opportunities
        recent_quantum_scores = [e.quantum_score for e in self.scaling_history[-10:]]
        if recent_quantum_scores and sum(recent_quantum_scores) / len(recent_quantum_scores) < 0.5:
            recommendations.append("Low quantum optimization scores - review quantum parameters")
        
        return recommendations


# Example usage
async def simulate_metrics():
    """Simulate metrics for testing"""
    base_cpu = 50
    base_memory = 60
    
    # Simulate varying load
    cpu_usage = base_cpu + random.uniform(-20, 30)
    memory_usage = base_memory + random.uniform(-15, 25)
    
    return ResourceMetrics(
        cpu_usage=max(0, min(100, cpu_usage)),
        memory_usage=max(0, min(100, memory_usage)),
        gpu_usage=random.uniform(20, 80),
        storage_usage=random.uniform(40, 60),
        network_io=random.uniform(30, 70),
        instance_count=2,
        request_rate=random.uniform(80, 120),
        response_time=random.uniform(0.05, 0.5),
        error_rate=random.uniform(0.001, 0.02),
        timestamp=time.time()
    )


async def main():
    """Example usage of the quantum scaling orchestrator"""
    orchestrator = QuantumScalingOrchestrator()
    
    # Simulate some scaling decisions
    for i in range(5):
        metrics = await simulate_metrics()
        recommendations = orchestrator.get_scaling_recommendations(metrics)
        
        print(f"\n--- Scaling Analysis {i+1} ---")
        print(json.dumps(recommendations, indent=2, default=str))
        
        await asyncio.sleep(1)
    
    # Generate final report
    report = orchestrator.generate_scaling_report()
    print("\n--- Final Scaling Report ---")
    print(json.dumps(report, indent=2, default=str))


if __name__ == "__main__":
    asyncio.run(main())