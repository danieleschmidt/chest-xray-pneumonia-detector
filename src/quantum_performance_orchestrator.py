#!/usr/bin/env python3
"""
Quantum Performance Orchestrator
Progressive Enhancement - Generation 3: MAKE IT SCALE
"""

import asyncio
import json
import logging
import time
import math
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Callable
import numpy as np
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

class OptimizationTarget(Enum):
    """Performance optimization targets"""
    LATENCY = "latency"
    THROUGHPUT = "throughput"
    MEMORY = "memory"
    CPU = "cpu"
    GPU = "gpu"
    ENERGY = "energy"
    COST = "cost"

class ScalingStrategy(Enum):
    """Auto-scaling strategies"""
    HORIZONTAL = "horizontal"
    VERTICAL = "vertical"
    ELASTIC = "elastic"
    PREDICTIVE = "predictive"
    QUANTUM_ADAPTIVE = "quantum_adaptive"

@dataclass
class PerformanceMetrics:
    """Real-time performance metrics"""
    timestamp: datetime = field(default_factory=datetime.now)
    latency_ms: float = 0.0
    throughput_ops_per_sec: float = 0.0
    cpu_utilization: float = 0.0
    memory_usage_mb: float = 0.0
    gpu_utilization: float = 0.0
    queue_depth: int = 0
    active_workers: int = 0
    error_rate: float = 0.0
    cost_per_operation: float = 0.0

@dataclass
class OptimizationResult:
    """Results of performance optimization"""
    optimization_id: str
    target: OptimizationTarget
    before_metrics: PerformanceMetrics
    after_metrics: PerformanceMetrics
    improvement_percentage: float
    applied_strategies: List[str]
    duration_ms: float
    timestamp: datetime = field(default_factory=datetime.now)

class QuantumPerformanceOrchestrator:
    """
    Quantum-inspired performance orchestrator with intelligent scaling.
    
    Features:
    - Real-time performance monitoring and optimization
    - Quantum-adaptive scaling algorithms
    - Multi-dimensional optimization (latency, throughput, cost)
    - Predictive resource allocation
    - Intelligent workload distribution
    - Energy-efficient computing
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._default_config()
        
        # Performance monitoring
        self.metrics_history: List[PerformanceMetrics] = []
        self.current_metrics = PerformanceMetrics()
        
        # Optimization state
        self.optimization_results: List[OptimizationResult] = []
        self.active_optimizations: Set[str] = set()
        self.resource_pools = {}
        
        # Scaling infrastructure
        self.worker_pools = {
            "cpu": ThreadPoolExecutor(max_workers=mp.cpu_count()),
            "io": ThreadPoolExecutor(max_workers=50),
            "compute": ProcessPoolExecutor(max_workers=mp.cpu_count())
        }
        
        # Quantum-adaptive parameters
        self.quantum_state = {
            "coherence_factor": 1.0,
            "entanglement_strength": 0.5,
            "superposition_states": [],
            "optimization_amplitude": 1.0
        }
        
        self.logger = self._setup_logging()
        self.is_monitoring = False
        
    def _default_config(self) -> Dict[str, Any]:
        """Default configuration for performance orchestrator"""
        return {
            "monitoring": {
                "metrics_interval_ms": 1000,
                "optimization_interval_ms": 30000,
                "history_retention_hours": 24
            },
            "scaling": {
                "min_workers": 1,
                "max_workers": 100,
                "scale_up_threshold": 0.8,
                "scale_down_threshold": 0.3,
                "cool_down_period_s": 300
            },
            "optimization": {
                "target_latency_ms": 100,
                "target_throughput": 1000,
                "target_cpu_util": 0.7,
                "target_memory_mb": 2048,
                "optimization_aggressiveness": 0.5
            },
            "quantum_adaptive": {
                "enable_quantum_optimization": True,
                "coherence_decay_rate": 0.01,
                "entanglement_threshold": 0.7,
                "superposition_collapse_probability": 0.1
            }
        }
        
    def _setup_logging(self) -> logging.Logger:
        """Setup performance monitoring logging"""
        logger = logging.getLogger("QuantumPerformance")
        logger.setLevel(logging.INFO)
        
        # Performance logs directory
        log_dir = Path("performance_logs")
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / f"performance_{datetime.now().strftime('%Y%m%d')}.log"
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(
            logging.Formatter(
                "%(asctime)s - PERFORMANCE - %(levelname)s - %(message)s"
            )
        )
        
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(
            logging.Formatter("PERF - %(levelname)s - %(message)s")
        )
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
        
    async def start_monitoring(self):
        """Start comprehensive performance monitoring"""
        if self.is_monitoring:
            return
            
        self.is_monitoring = True
        self.logger.info("Starting quantum performance monitoring")
        
        # Start monitoring tasks
        tasks = [
            asyncio.create_task(self._metrics_collection_loop()),
            asyncio.create_task(self._optimization_loop()),
            asyncio.create_task(self._quantum_state_evolution()),
            asyncio.create_task(self._predictive_scaling_loop())
        ]
        
        await asyncio.gather(*tasks, return_exceptions=True)
        
    async def _metrics_collection_loop(self):
        """Collect performance metrics continuously"""
        while self.is_monitoring:
            try:
                metrics = await self._collect_current_metrics()
                self.current_metrics = metrics
                self.metrics_history.append(metrics)
                
                # Limit history size
                retention_hours = self.config["monitoring"]["history_retention_hours"]
                cutoff_time = datetime.now() - timedelta(hours=retention_hours)
                self.metrics_history = [
                    m for m in self.metrics_history if m.timestamp > cutoff_time
                ]
                
                await asyncio.sleep(self.config["monitoring"]["metrics_interval_ms"] / 1000)
                
            except Exception as e:
                self.logger.error(f"Metrics collection error: {e}")
                await asyncio.sleep(1)
                
    async def _collect_current_metrics(self) -> PerformanceMetrics:
        """Collect current system performance metrics"""
        # Mock metrics collection - in production would use actual monitoring
        return PerformanceMetrics(
            latency_ms=np.random.uniform(50, 200),
            throughput_ops_per_sec=np.random.uniform(800, 1200),
            cpu_utilization=np.random.uniform(0.3, 0.9),
            memory_usage_mb=np.random.uniform(1000, 3000),
            gpu_utilization=np.random.uniform(0.2, 0.8),
            queue_depth=np.random.randint(0, 50),
            active_workers=np.random.randint(5, 20),
            error_rate=np.random.uniform(0.0, 0.05),
            cost_per_operation=np.random.uniform(0.001, 0.01)
        )
        
    async def _optimization_loop(self):
        """Continuous performance optimization loop"""
        while self.is_monitoring:
            try:
                if len(self.metrics_history) >= 5:  # Need some history
                    await self._run_optimization_cycle()
                    
                await asyncio.sleep(self.config["monitoring"]["optimization_interval_ms"] / 1000)
                
            except Exception as e:
                self.logger.error(f"Optimization loop error: {e}")
                await asyncio.sleep(5)
                
    async def _run_optimization_cycle(self):
        """Run comprehensive optimization cycle"""
        optimization_id = f"opt_{int(time.time() * 1000)}"
        self.logger.info(f"Starting optimization cycle: {optimization_id}")
        
        start_time = time.time()
        before_metrics = self.current_metrics
        
        # Analyze performance bottlenecks
        bottlenecks = await self._analyze_performance_bottlenecks()
        
        # Apply quantum-adaptive optimizations
        applied_strategies = []
        
        for bottleneck in bottlenecks:
            strategy = await self._select_optimization_strategy(bottleneck)
            success = await self._apply_optimization(strategy, bottleneck)
            
            if success:
                applied_strategies.append(strategy)
                
        # Measure optimization impact
        await asyncio.sleep(2)  # Let metrics stabilize
        after_metrics = await self._collect_current_metrics()
        
        # Calculate improvement
        improvement = self._calculate_improvement(before_metrics, after_metrics)
        
        # Record optimization result
        result = OptimizationResult(
            optimization_id=optimization_id,
            target=self._determine_primary_target(bottlenecks),
            before_metrics=before_metrics,
            after_metrics=after_metrics,
            improvement_percentage=improvement,
            applied_strategies=applied_strategies,
            duration_ms=(time.time() - start_time) * 1000
        )
        
        self.optimization_results.append(result)
        
        self.logger.info(
            f"Optimization cycle complete: {optimization_id} - "
            f"Improvement: {improvement:.2f}% - "
            f"Strategies: {len(applied_strategies)}"
        )
        
    async def _analyze_performance_bottlenecks(self) -> List[Dict[str, Any]]:
        """Analyze current performance bottlenecks"""
        recent_metrics = self.metrics_history[-10:]  # Last 10 measurements
        if not recent_metrics:
            return []
            
        bottlenecks = []
        config = self.config["optimization"]
        
        # Latency analysis
        avg_latency = np.mean([m.latency_ms for m in recent_metrics])
        if avg_latency > config["target_latency_ms"]:
            bottlenecks.append({
                "type": "latency",
                "severity": min(avg_latency / config["target_latency_ms"], 3.0),
                "current_value": avg_latency,
                "target_value": config["target_latency_ms"]
            })
            
        # Throughput analysis
        avg_throughput = np.mean([m.throughput_ops_per_sec for m in recent_metrics])
        if avg_throughput < config["target_throughput"]:
            bottlenecks.append({
                "type": "throughput",
                "severity": config["target_throughput"] / max(avg_throughput, 1),
                "current_value": avg_throughput,
                "target_value": config["target_throughput"]
            })
            
        # CPU utilization analysis
        avg_cpu = np.mean([m.cpu_utilization for m in recent_metrics])
        if avg_cpu > config["target_cpu_util"]:
            bottlenecks.append({
                "type": "cpu",
                "severity": avg_cpu / config["target_cpu_util"],
                "current_value": avg_cpu,
                "target_value": config["target_cpu_util"]
            })
            
        # Memory analysis
        avg_memory = np.mean([m.memory_usage_mb for m in recent_metrics])
        if avg_memory > config["target_memory_mb"]:
            bottlenecks.append({
                "type": "memory",
                "severity": avg_memory / config["target_memory_mb"],
                "current_value": avg_memory,
                "target_value": config["target_memory_mb"]
            })
            
        # Sort by severity
        bottlenecks.sort(key=lambda x: x["severity"], reverse=True)
        
        return bottlenecks[:3]  # Top 3 bottlenecks
        
    async def _select_optimization_strategy(self, bottleneck: Dict[str, Any]) -> str:
        """Select optimal strategy for bottleneck using quantum-adaptive algorithm"""
        bottleneck_type = bottleneck["type"]
        severity = bottleneck["severity"]
        
        # Quantum-influenced strategy selection
        quantum_factor = self._calculate_quantum_optimization_factor()
        
        strategy_weights = {
            "latency": {
                "cache_optimization": 0.3 * quantum_factor,
                "algorithm_acceleration": 0.25,
                "parallel_processing": 0.2,
                "memory_optimization": 0.15,
                "network_optimization": 0.1
            },
            "throughput": {
                "horizontal_scaling": 0.35 * quantum_factor,
                "batch_optimization": 0.25,
                "pipeline_parallelism": 0.2,
                "resource_pooling": 0.15,
                "load_balancing": 0.05
            },
            "cpu": {
                "workload_distribution": 0.3 * quantum_factor,
                "process_optimization": 0.25,
                "scheduling_improvement": 0.2,
                "algorithm_efficiency": 0.15,
                "cooling_strategies": 0.1
            },
            "memory": {
                "garbage_collection": 0.3 * quantum_factor,
                "memory_pooling": 0.25,
                "data_compression": 0.2,
                "cache_management": 0.15,
                "memory_mapping": 0.1
            }
        }
        
        # Select strategy based on weighted probabilities
        strategies = strategy_weights.get(bottleneck_type, {})
        if not strategies:
            return "default_optimization"
            
        # Apply severity multiplier
        adjusted_weights = {k: v * (1 + severity * 0.2) for k, v in strategies.items()}
        
        # Quantum superposition collapse to select strategy
        total_weight = sum(adjusted_weights.values())
        random_value = np.random.random() * total_weight
        
        cumulative_weight = 0
        for strategy, weight in adjusted_weights.items():
            cumulative_weight += weight
            if random_value <= cumulative_weight:
                return strategy
                
        return list(strategies.keys())[0]  # Fallback
        
    def _calculate_quantum_optimization_factor(self) -> float:
        """Calculate quantum-inspired optimization factor"""
        coherence = self.quantum_state["coherence_factor"]
        entanglement = self.quantum_state["entanglement_strength"]
        amplitude = self.quantum_state["optimization_amplitude"]
        
        # Quantum interference pattern
        interference = math.cos(time.time() * 0.1) * 0.2 + 1.0
        
        return coherence * entanglement * amplitude * interference
        
    async def _apply_optimization(self, strategy: str, bottleneck: Dict[str, Any]) -> bool:
        """Apply selected optimization strategy"""
        self.logger.info(f"Applying optimization: {strategy} for {bottleneck['type']}")
        
        try:
            # Strategy implementations
            optimization_functions = {
                "cache_optimization": self._optimize_caching,
                "algorithm_acceleration": self._accelerate_algorithms,
                "parallel_processing": self._optimize_parallelism,
                "horizontal_scaling": self._scale_horizontally,
                "batch_optimization": self._optimize_batching,
                "workload_distribution": self._distribute_workload,
                "garbage_collection": self._optimize_gc,
                "memory_pooling": self._optimize_memory_pools,
                "default_optimization": self._default_optimization
            }
            
            optimization_func = optimization_functions.get(strategy, self._default_optimization)
            result = await optimization_func(bottleneck)
            
            if result:
                self.logger.info(f"Optimization {strategy} applied successfully")
            else:
                self.logger.warning(f"Optimization {strategy} failed")
                
            return result
            
        except Exception as e:
            self.logger.error(f"Optimization {strategy} error: {e}")
            return False
            
    async def _optimize_caching(self, bottleneck: Dict[str, Any]) -> bool:
        """Optimize caching strategies"""
        # Mock caching optimization
        await asyncio.sleep(0.1)
        self.logger.info("Cache optimization applied: intelligent prefetching, TTL tuning")
        return True
        
    async def _accelerate_algorithms(self, bottleneck: Dict[str, Any]) -> bool:
        """Accelerate core algorithms"""
        await asyncio.sleep(0.2)
        self.logger.info("Algorithm acceleration: vectorization, GPU offloading")
        return True
        
    async def _optimize_parallelism(self, bottleneck: Dict[str, Any]) -> bool:
        """Optimize parallel processing"""
        current_workers = self.current_metrics.active_workers
        optimal_workers = min(current_workers * 1.5, self.config["scaling"]["max_workers"])
        
        # Simulate scaling
        await asyncio.sleep(0.1)
        self.logger.info(f"Parallelism optimized: scaled to {optimal_workers} workers")
        return True
        
    async def _scale_horizontally(self, bottleneck: Dict[str, Any]) -> bool:
        """Apply horizontal scaling"""
        await asyncio.sleep(0.3)
        self.logger.info("Horizontal scaling: additional compute nodes allocated")
        return True
        
    async def _optimize_batching(self, bottleneck: Dict[str, Any]) -> bool:
        """Optimize batch processing"""
        await asyncio.sleep(0.1)
        self.logger.info("Batch optimization: dynamic batch sizing, pipelining")
        return True
        
    async def _distribute_workload(self, bottleneck: Dict[str, Any]) -> bool:
        """Optimize workload distribution"""
        await asyncio.sleep(0.1)
        self.logger.info("Workload distribution: intelligent load balancing")
        return True
        
    async def _optimize_gc(self, bottleneck: Dict[str, Any]) -> bool:
        """Optimize garbage collection"""
        await asyncio.sleep(0.05)
        self.logger.info("Memory optimization: GC tuning, memory pools")
        return True
        
    async def _optimize_memory_pools(self, bottleneck: Dict[str, Any]) -> bool:
        """Optimize memory pool management"""
        await asyncio.sleep(0.1)
        self.logger.info("Memory pools optimized: pre-allocation, recycling")
        return True
        
    async def _default_optimization(self, bottleneck: Dict[str, Any]) -> bool:
        """Default optimization strategy"""
        await asyncio.sleep(0.05)
        self.logger.info("Default optimization applied")
        return True
        
    def _calculate_improvement(self, before: PerformanceMetrics, 
                             after: PerformanceMetrics) -> float:
        """Calculate overall performance improvement percentage"""
        improvements = []
        
        # Latency improvement (lower is better)
        if before.latency_ms > 0:
            latency_improvement = (before.latency_ms - after.latency_ms) / before.latency_ms * 100
            improvements.append(latency_improvement)
            
        # Throughput improvement (higher is better)
        if before.throughput_ops_per_sec > 0:
            throughput_improvement = (after.throughput_ops_per_sec - before.throughput_ops_per_sec) / before.throughput_ops_per_sec * 100
            improvements.append(throughput_improvement)
            
        # CPU improvement (lower utilization is better if performance maintained)
        if before.cpu_utilization > 0 and after.throughput_ops_per_sec >= before.throughput_ops_per_sec:
            cpu_improvement = (before.cpu_utilization - after.cpu_utilization) / before.cpu_utilization * 100
            improvements.append(cpu_improvement)
            
        # Memory improvement (lower is better)
        if before.memory_usage_mb > 0:
            memory_improvement = (before.memory_usage_mb - after.memory_usage_mb) / before.memory_usage_mb * 100
            improvements.append(memory_improvement)
            
        return np.mean(improvements) if improvements else 0.0
        
    def _determine_primary_target(self, bottlenecks: List[Dict[str, Any]]) -> OptimizationTarget:
        """Determine primary optimization target"""
        if not bottlenecks:
            return OptimizationTarget.LATENCY
            
        target_map = {
            "latency": OptimizationTarget.LATENCY,
            "throughput": OptimizationTarget.THROUGHPUT,
            "cpu": OptimizationTarget.CPU,
            "memory": OptimizationTarget.MEMORY
        }
        
        return target_map.get(bottlenecks[0]["type"], OptimizationTarget.LATENCY)
        
    async def _quantum_state_evolution(self):
        """Evolve quantum state parameters for adaptive optimization"""
        while self.is_monitoring:
            try:
                # Coherence decay
                decay_rate = self.config["quantum_adaptive"]["coherence_decay_rate"]
                self.quantum_state["coherence_factor"] *= (1 - decay_rate)
                self.quantum_state["coherence_factor"] = max(0.1, self.quantum_state["coherence_factor"])
                
                # Entanglement evolution
                performance_trend = self._calculate_performance_trend()
                if performance_trend > 0:
                    self.quantum_state["entanglement_strength"] = min(1.0, 
                        self.quantum_state["entanglement_strength"] + 0.01)
                else:
                    self.quantum_state["entanglement_strength"] = max(0.1,
                        self.quantum_state["entanglement_strength"] - 0.01)
                        
                # Amplitude modulation
                self.quantum_state["optimization_amplitude"] = 0.5 + 0.5 * math.sin(time.time() * 0.05)
                
                await asyncio.sleep(10)  # Update every 10 seconds
                
            except Exception as e:
                self.logger.error(f"Quantum state evolution error: {e}")
                await asyncio.sleep(5)
                
    def _calculate_performance_trend(self) -> float:
        """Calculate recent performance trend"""
        if len(self.metrics_history) < 10:
            return 0.0
            
        recent = self.metrics_history[-5:]
        older = self.metrics_history[-10:-5]
        
        recent_avg = np.mean([m.throughput_ops_per_sec for m in recent])
        older_avg = np.mean([m.throughput_ops_per_sec for m in older])
        
        return (recent_avg - older_avg) / max(older_avg, 1.0)
        
    async def _predictive_scaling_loop(self):
        """Predictive scaling based on performance patterns"""
        while self.is_monitoring:
            try:
                if len(self.metrics_history) >= 20:
                    await self._run_predictive_scaling()
                    
                await asyncio.sleep(60)  # Run every minute
                
            except Exception as e:
                self.logger.error(f"Predictive scaling error: {e}")
                await asyncio.sleep(30)
                
    async def _run_predictive_scaling(self):
        """Run predictive scaling analysis and actions"""
        # Analyze patterns in metrics history
        recent_metrics = self.metrics_history[-20:]
        
        # Predict future load based on trends
        throughput_values = [m.throughput_ops_per_sec for m in recent_metrics]
        latency_values = [m.latency_ms for m in recent_metrics]
        
        # Simple linear trend analysis
        throughput_trend = np.polyfit(range(len(throughput_values)), throughput_values, 1)[0]
        latency_trend = np.polyfit(range(len(latency_values)), latency_values, 1)[0]
        
        # Predict scaling needs
        if throughput_trend > 50:  # Increasing load
            self.logger.info("Predictive scaling: Increasing load detected, pre-scaling resources")
            await self._proactive_scale_up()
        elif throughput_trend < -50:  # Decreasing load
            self.logger.info("Predictive scaling: Decreasing load detected, preparing scale down")
            await self._proactive_scale_down()
            
        if latency_trend > 5:  # Increasing latency
            self.logger.info("Predictive scaling: Latency degradation predicted, applying optimizations")
            await self._proactive_latency_optimization()
            
    async def _proactive_scale_up(self):
        """Proactively scale up resources"""
        # Mock scaling up
        await asyncio.sleep(0.1)
        self.logger.info("Proactive scale-up: Additional resources allocated")
        
    async def _proactive_scale_down(self):
        """Proactively scale down resources"""
        await asyncio.sleep(0.1)
        self.logger.info("Proactive scale-down: Resources deallocated to reduce costs")
        
    async def _proactive_latency_optimization(self):
        """Proactively optimize for latency"""
        await asyncio.sleep(0.1)
        self.logger.info("Proactive latency optimization: Cache warming, connection pooling")
        
    def get_performance_dashboard(self) -> Dict[str, Any]:
        """Get comprehensive performance dashboard"""
        recent_optimizations = [
            {
                "id": result.optimization_id,
                "target": result.target.value,
                "improvement": result.improvement_percentage,
                "strategies": result.applied_strategies,
                "duration_ms": result.duration_ms,
                "timestamp": result.timestamp.isoformat()
            }
            for result in self.optimization_results[-5:]  # Last 5 optimizations
        ]
        
        # Calculate performance trends
        performance_trend = self._calculate_performance_trend()
        
        return {
            "status": "monitoring" if self.is_monitoring else "stopped",
            "current_metrics": {
                "latency_ms": self.current_metrics.latency_ms,
                "throughput_ops_per_sec": self.current_metrics.throughput_ops_per_sec,
                "cpu_utilization": self.current_metrics.cpu_utilization,
                "memory_usage_mb": self.current_metrics.memory_usage_mb,
                "gpu_utilization": self.current_metrics.gpu_utilization,
                "active_workers": self.current_metrics.active_workers,
                "error_rate": self.current_metrics.error_rate
            },
            "optimization_summary": {
                "total_optimizations": len(self.optimization_results),
                "successful_optimizations": len([r for r in self.optimization_results if r.improvement_percentage > 0]),
                "average_improvement": np.mean([r.improvement_percentage for r in self.optimization_results]) if self.optimization_results else 0,
                "performance_trend": performance_trend
            },
            "quantum_state": self.quantum_state,
            "recent_optimizations": recent_optimizations,
            "resource_utilization": {
                "cpu_workers": self.worker_pools["cpu"]._threads if hasattr(self.worker_pools["cpu"], '_threads') else 0,
                "io_workers": self.worker_pools["io"]._threads if hasattr(self.worker_pools["io"], '_threads') else 0,
                "compute_processes": len(self.worker_pools["compute"]._processes) if hasattr(self.worker_pools["compute"], '_processes') else 0
            },
            "timestamp": datetime.now().isoformat()
        }
        
    async def stop_monitoring(self):
        """Stop performance monitoring gracefully"""
        self.is_monitoring = False
        
        # Cleanup worker pools
        self.worker_pools["cpu"].shutdown(wait=True)
        self.worker_pools["io"].shutdown(wait=True)
        self.worker_pools["compute"].shutdown(wait=True)
        
        self.logger.info("Quantum performance monitoring stopped")


async def demo_quantum_performance_orchestrator():
    """Demonstrate the Quantum Performance Orchestrator"""
    print("âš¡ Quantum Performance Orchestrator Demo")
    print("=" * 50)
    
    # Initialize orchestrator
    orchestrator = QuantumPerformanceOrchestrator()
    
    try:
        # Start monitoring
        print("\nðŸš€ Starting performance monitoring...")
        monitoring_task = asyncio.create_task(orchestrator.start_monitoring())
        
        # Let it run and optimize for demo period
        print("ðŸ“Š Collecting metrics and running optimizations...")
        await asyncio.sleep(15)  # Run for 15 seconds
        
        # Get performance dashboard
        print("\nðŸ“ˆ Performance Dashboard:")
        dashboard = orchestrator.get_performance_dashboard()
        
        current = dashboard["current_metrics"]
        print(f"Current Performance:")
        print(f"  Latency: {current['latency_ms']:.2f}ms")
        print(f"  Throughput: {current['throughput_ops_per_sec']:.1f} ops/sec")
        print(f"  CPU Utilization: {current['cpu_utilization']:.1%}")
        print(f"  Memory Usage: {current['memory_usage_mb']:.1f}MB")
        print(f"  Active Workers: {current['active_workers']}")
        
        summary = dashboard["optimization_summary"]
        print(f"\nOptimization Summary:")
        print(f"  Total Optimizations: {summary['total_optimizations']}")
        print(f"  Successful: {summary['successful_optimizations']}")
        print(f"  Average Improvement: {summary['average_improvement']:.2f}%")
        print(f"  Performance Trend: {summary['performance_trend']:.3f}")
        
        print(f"\nQuantum State:")
        quantum = dashboard["quantum_state"]
        print(f"  Coherence Factor: {quantum['coherence_factor']:.3f}")
        print(f"  Entanglement Strength: {quantum['entanglement_strength']:.3f}")
        print(f"  Optimization Amplitude: {quantum['optimization_amplitude']:.3f}")
        
        if dashboard['recent_optimizations']:
            print(f"\nRecent Optimizations:")
            for opt in dashboard['recent_optimizations'][-3:]:
                print(f"  ðŸ”§ Target: {opt['target']} - "
                      f"Improvement: {opt['improvement']:.2f}% - "
                      f"Strategies: {len(opt['strategies'])}")
                      
    finally:
        await orchestrator.stop_monitoring()
        print("\nâœ… Quantum performance orchestrator demo complete")


if __name__ == "__main__":
    # Fix for Windows/multiprocessing
    mp.set_start_method('spawn', force=True)
    asyncio.run(demo_quantum_performance_orchestrator())